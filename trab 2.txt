from numba import cuda

import numpy

from numpy import *
threads_per_block = 16
@cuda.jit
def my_kernel( matriz_a, matriz_b, matriz_c):
    
    sA = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)
    sB = cuda.shared.array(shape=(threads_per_block, threads_per_block), dtype=float32)

    x, y = cuda.grid(2)
    # Thread id in a 1D block
    tx = cuda.threadIdx.x
    # Block id in a 1D grid
    ty = cuda.threadIdx.y
    # Block width, i.e. number of threads per block
    bw = cuda.gridDim.x
    
    # Compute flattened index inside the array
    if x >= matriz_c.shape[0] and y >= matriz_c.shape[1]:
        # Quit if (x, y) is outside of valid C boundary
        return
    tmp = 0.
    
    for i in range(bw):
      sA[tx, ty] = matriz_a[x, i ]
      sB[tx, ty] = matriz_b[i , y]
      
      for j in range(threads_per_block):
        tmp += sA[tx, j] * sB[j, ty]
      
        matriz_c[x, y] = tmp  


# n√∫mero de blocos por grid
blocks_per_grid = ( 2 + (threads_per_block - 1) )
matriz_a = [ [2, 3], [1, 0] ]

matriz_b = [ [3, 1], [2, 4] ]

a = numpy.array(matriz_a)
b = numpy.array(matriz_b)

matriz_c =  [ [0, 0], [0, 0]]
c = numpy.array(matriz_c)

# iniciando o kernel
my_kernel[blocks_per_grid, threads_per_block](a, b, c)

print(c)

